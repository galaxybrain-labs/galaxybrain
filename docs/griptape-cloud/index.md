# Griptape Cloud

[Griptape Cloud](https://cloud.griptape.ai/) provides managed services for your AI app stack. Deploy and scale end-to-end solutions, from LLM-powered data prep and retrieval to AI Agents, Pipelines, and Workflows.

## Build Your Own RAG Pipeline

Connect to your data with [Data Sources](data-sources/what-are-data-sources.md), store files in [Data Lakes](data-lakes/data-lakes.md), and prepare them for retrieval with [Knowledge Bases](knowledge-bases/create-knowledge-base.md).

## Host and Run Your Code

Have Griptape code? Have existing code with another LLM framework? You can host your Python code using [Structures](structures/create-structure.md) whether it uses the Griptape Framework or not.

## Augment Agents with Tools

Expand the capabilities of your agents with custom Tools they can use. These Tools allow them to call services or perform custom logic, bridging the gap between the LLM and your application. Tools can even be used to augment other applications like [OpenAI's GPTs via OpenAI Actions](https://platform.openai.com/docs/actions/introduction). See [Tools](tools/create-tool.md) to get started.

## Store Configuration for LLM Agents

[Rules and Rulesets](rules/rulesets.md) enable rapid and collabortive iteration for managing LLM behavior. [Threads and Messages](threads/threads.md) allow for persisted and editable conversation memory across any LLM invocation.

## APIs

All of our features can be called via API with a [Griptape Cloud API Key](https://cloud.griptape.ai/configuration/api-keys). See the [API Reference](api/api-reference.md) for detailed information.
